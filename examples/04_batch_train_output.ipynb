{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "\n",
    "# PhotonTorch\n",
    "import photontorch as pt\n",
    "\n",
    "# Progress Bars\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michelson Interferometer Cavity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schematic\n",
    "![michelson interferometer](images/michelson.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation and Design Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_batches = 404 # number of parallel simulations to perform\n",
    "neff = np.sqrt(12.1)\n",
    "wl = 1.55e-6\n",
    "dt = 0.5e-9\n",
    "total_time = 2e-6\n",
    "time = np.arange(0,total_time,dt)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same network as in the [previous notebook](04_train_output.ipynb). However, the network can be put on the `GPU` with the `to(\"cuda\")` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network in the standard way:\n",
    "class MichelsonCavity(pt.Network):\n",
    "    def __init__(self):\n",
    "        super(MichelsonCavity, self).__init__(copy_components=True)\n",
    "        self.west = pt.Source()\n",
    "        self.north = self.east = self.south = pt.Detector()\n",
    "        self.m_west = self.m_north = self.m_east = self.m_south = pt.Mirror(R=0.9)\n",
    "        self.wg_west = pt.Waveguide(0.43, neff=neff)\n",
    "        self.wg_north = pt.Waveguide(0.60, neff=neff)\n",
    "        self.wg_east = pt.Waveguide(0.95, neff=neff)\n",
    "        self.wg_south = pt.Waveguide(1.12, neff=neff)\n",
    "        self.dc = pt.DirectionalCoupler(coupling=0.5)\n",
    "        self.link('west:0','0:m_west:1', '0:wg_west:1', '0:dc:2', '0:wg_east:1', '0:m_east:1', '0:east')\n",
    "        self.link('north:0', '0:m_north:1', '0:wg_north:1', '1:dc:3', '0:wg_south:1', '0:m_south:1', '0:south')\n",
    "    \n",
    "# create network\n",
    "nw = MichelsonCavity().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another power of Photontorch is the massive parallelism one can achieve by doing multiple simulations at once (called batches):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_weights = np.random.random(num_batches)\n",
    "with pt.Environment(wl=wl, t=time, num_batches=num_batches):\n",
    "    detected = nw(source=batch_weights)[:,0,:,:]   # get all timesteps, the only wavelength, all detectors, all batches\n",
    "    nw.plot(detected[:,:,[1,3]]); #plot second and fourth batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "learning_rate = 0.2\n",
    "lossfunc = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(nw.parameters(), lr=learning_rate)\n",
    "env = pt.Environment(wl=wl, t=time, num_batches=num_batches) # training environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to train the network to arrive in another steady state with the same output everywhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_power_out = detected.data.cpu().numpy()[-1].sum()\n",
    "target = torch.tensor(torch.cat([detected.data[-1].mean(0, keepdim=True)]*3, dim=0), device=nw.device)\n",
    "del detected # Free up GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train (CUDA is recommended here...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running speed without cuda: 27s/it\n",
    "# Running speed with cuda: 3.5s/it\n",
    "# loop over the training cycles:\n",
    "with pt.Environment(wavelength=wl, t=time, enable_grad=True):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        detected = nw(source=batch_weights)[-1,0,:,:] # get the last timestep, the only wavelength, all detectors, all batches\n",
    "        loss = lossfunc(detected, target) # calculate the loss (error) between detected and target\n",
    "        loss.backward() # calculate the resulting gradients for all the parameters of the network\n",
    "        optimizer.step() # update the networks parameters with the gradients\n",
    "        del detected, loss # free up memory (important for GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a final simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pt.Environment(wl=wl, t=time, num_batches=num_batches):\n",
    "    detected = nw(source=batch_weights)\n",
    "    nw.plot(detected[:,0,:,[1,3]]); #plot second and fourth batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
